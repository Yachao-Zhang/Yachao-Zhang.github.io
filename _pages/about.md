---
permalink: /
title: "Yachao Zhang(Âº†‰∫öË∂Ö)"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

üåà I am a postdoctoral researcher at the Intelligent Computing Lab, SIGS of Tsinghua University, working with Prof. Xiu Li (ÊùéÁßÄÊïôÊéà). Previously, I did my Ph.D. from September 2018 to June 2022 at the School of Informatics, at Xiamen University, China, supervised by Professor Cuihua Li (ÊùéÁø†ÂçéÊïôÊéà) and co-supervised by Professor Yanyun Qu (Êõ≤Âª∂‰∫ëÊïôÊéà). I received the M.S. degree in Control Theory and Control Engineering from Lanzhou University of Technology, China, in 2018, supervised by Professor Ce Li (ÊùéÁ≠ñÊïôÊéà).

üè≥Ô∏è‚Äçüåà My research interests include, but are not limited to: **Computer Vision** (3D computer vision, point cloud semantic segmentation), **Machine Learning** (weakly-supervised learning, unsupervised learning, transfer learning). Recently, I also focus on digital human avatar, including 3D human pose reconstruction, multimodality-driven 3D human motion generation. If you are interested in my research or have any use cases that you want to share, feel free to contact me!

_______________________________________________________________________________________________________
<h3>
  <a name="news"></a> ‚úçNews
</h3>
<div class="mini">
  <ul>
  <li> <strong>[Sep 2024]</strong> Three papers about multi-modal learning are accepted by NeurIPS 2024!</li>
  <li> <strong>[Aug 2024]</strong> Three papers about multi-modal learning are accepted by ACMMM 2024!</li>
  <li> <strong>[Jul 2024]</strong> One paper about multi-modal label efficient learning is accepted by ECCV 2024!</li>
  <li> <strong>[Jun 2024]</strong> One paper about Object Detection is accepted by TNNLS!</li>
  <li> <strong>[Feb 2024]</strong> One paper about AI ChoreoMaster is accepted by CVPR 2024!</li>
  <li> <strong>[Jan 2024]</strong> One papers about about camouflaged object detection is accepted by ICLR 2024!</li>
  <li> <strong>[Dec 2023]</strong> Three papers about digital human avatar and cross-modal zero-shot learning are accepted by ICASSP 2024!</li>
  <li> <strong>[Dec 2023]</strong> Two papers about multi-modal understanding and multi-modal gestures generation are accepted by AAAI 2024!</li>
  <li> <strong>[Oct 2023]</strong> Our paper about Semi-Supervised Defect Segmentation is accepted by TNNLS!</li>
  <li> <strong>[Sep 2023]</strong> One paper about weakly supervised learning is accepted by NeurIPS 2023!</li>
  <li> <strong>[Aug 2023]</strong> My application of the National Natural Science Foundation of China is approved!</li>
  <li> <strong>[Jul 2023]</strong> One paper about multi-modal unsupervised domain adaptation semantic segmentation is accepted by ACMMM 2023!</li>
  <li> <strong>[Jul 2023]</strong> Four papers about multi-modal learning, ANN2SNN, and  <a href="https://li-ronghui.github.io/finedance.html">AI ChoreoMaster</a> are accepted by ICCV 2023!</li>
  <li> <strong>[Jun 2023]</strong> My application of the China Postdoctoral Science Foundation is approved!</li>
  <li> <strong>[Apr 2023]</strong> One paper about zero-shot learning is accepted by IJCAI 2023!</li>
  <li> <strong>[Mar 2023]</strong> One paper about camouflaged object detection is accepted by CVPR 2023!</li>
  <li> <strong>[Feb 2023]</strong> One paper about long-tailed learning is accepted by ICASSP 2023!</li>
  <li> <strong>[Nov 2022]</strong> One paper about weakly-supervised point cloud semantic segmentation is accepted by AAAI 2023!</li>
  <li> <strong>[Aug 2022]</strong> One paper about binary multi-view cluster is accepted by TNNLS!</li>
  <li> <strong>[Jul 2022]</strong> Two papers about multi-modal unsupervised domain adaptation semantic segmentation are accepted by ACMMM 2022!</li>
  <li> <strong>[Jun 2022]</strong> I am the winner of the title of "Outstanding Graduate" of Xiamen University!</li>
  <li> <strong>[Jun 2022]</strong> I successfully defended my PhD thesis!</li>
  <li> <strong>[Mar 2022]</strong> I am the winner of Xiamen University Liu Yubin Youth Science and Technology Scholarship!</li>
  <li> <strong>[Nov 2021]</strong> I am the winner of the title of "Outstanding Student" of Xiamen University!</li>
  <li> <strong>[Dec 2021]</strong> I am the winner of the first prize of the 2021 Excellent Paper Award of Fujian Computer Society!</li>
  <li> <strong>[Jul 2021]</strong> One paper about weakly-supervised point cloud  semantic segmentation is accepted by ICCV 2021!</li>
  <li> <strong>[Mar 2021]</strong> One paper about PolSAR Image Classification is accepted by Remote Sensing!</li>
  <li> <strong>[Dec 2020]</strong> One paper about weakly-supervised large scale point cloud semantic segmentation is accepted by AAAI 2021!</li>
  </ul>
</div>

<style>
table, th, td {
  border: none;
  border-collapse: collapse;
}
</style>

_______________________________________________________________________________________________________

<h3>
  <a name="Publications"></a> üìöSelected Publications (1Ô∏è‚É£ Equal contribution, üìß Corresponding author)
</h3>

<font face="helvetica, ariel, &#39;sans serif&#39;">
        <table cellspacing="0" cellpadding="0" class="noBorder">
           <tbody>
            <tr>
                    <td class="noBorder" width="40%">
                        <img width="320" src="../images/PSD.jpg" border="0">
                            </td>
                    <td>
                      <b>Perturbed Self-Distillation: Weakly Supervised Large-Scale Point Cloud Semantic Segmentation </b>
                      <br>
                      <strong>Yachao Zhang</strong>, Yanyun Qu, Zhonghao Li, Shanshan Zheng, Cuihua Li. 
                      <br>
                      <em>IEEE Conference on International Conference on Computer Vision (ICCV 2021)</em>
                      <br>
                      [<a href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_Perturbed_Self-Distillation_Weakly_Supervised_Large-Scale_Point_Cloud_Semantic_Segmentation_ICCV_2021_paper.html">Paper</a>][<a href="https://github.com/Yachao-Zhang/PSD">Code</a>]
              </td>
           </tr>
           <tr>
                    <td class="noBorder" width="40%">
                        <img width="320" src="../images/WS3.jpg" border="0">
                            </td>
                    <td>
                    <b>Weakly supervised semantic segmentation for large-scale point cloud </b>
                    <br>
                    <strong>Yachao Zhang</strong>, Zonghao Li, Yuan Xie, Yanyun Qu, Cuihua Li, Tao Mei. 
                    <br>
                    <em>Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI 2021)</em>
                    <br>
                    [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/16455">Paper</a>][<a href="https://github.com/Yachao-Zhang/WS3">Code</a>]
                    </td>
             </tr>
             <tr>
                    <td width="40%">
                        <img width="320" src="../images/SSE-xMUDA.jpg" border="0">
                            </td>
                    <td>
                    <b>SSE-xMUDA: Self-supervised Exclusive Learning for 3D Segmentation in Cross-Modal Unsupervised Domain Adaptation </b>
                    <br>
                    <strong>Yachao Zhang</strong>,Miaoyu Li, Yuan Xie, Zhizhong Zhang, Cuihua Li, Yanyun Qu.
                    <br>
                    <em>ACM International Conference on Multimedia (ACMMM 2022)</em>
                    <br>
                    [<a href="https://doi.org/10.1145/3503161.3547987">Paper</a>][<a href="https://github.com/Yachao-Zhang/SSE-xMUDA">Code</a>]
                    </td>
                </tr>
                    <tr>
                    <td width="40%">
                        <img width="320" src="../images/dual-cross.jpg" border="0">
                            </td>
                    <td>
                            <b>Cross-Domain and Cross-Modal Knowledge Distillation in Domain Adaptation for 3D Semantic Segmentation</b>
                    <br>
                    Miaoyu Li<strong>1Ô∏è‚É£</strong>,<strong>Yachao Zhang1Ô∏è‚É£</strong>,Miaoyu Li, Yuan Xie, Zhizhong Zhang, Cuihua Li, Yanyun Qu. 
                    <br>
                    <em>ACM International Conference on Multimedia (ACMMM 2022)</em>
                    <br>
                   [<a href="https://dl.acm.org/doi/10.1145/3503161.3547990">Paper</a>][<a href="https://github.com/Yachao-Zhang/Dual-Cross">Code</a>]
                    </td>
               </tr>
                    <tr>
                    <td width="40%">
                        <img width="320" src="../images/all-in.png" border="0">
                            </td>
                    <td>
                            <b>Learning All-In Collaborative Multiview Binary Representation for Clustering</b>
                    <br>
                    <strong>Yachao Zhang</strong>, Yuan Xie, Zongze Wu, Cuihua Li, Yanyun Qu. 
                    <br>
                    <em>Transactions on Neural Networks and Learning Systems (TNNLS 2022)</em>
                    <br>
                    [<a href="https://ieeexplore.ieee.org/document/9882008/">Paper</a>][<a href="https://github.com/Yachao-Zhang/All_In_Learning">Code</a>]
                    </td>
               </tr>  
                    <tr>
                    <td width="40%">
                        <img width="320" src="../images/DoubleConsistency.png" border="0">
                            </td>
                    <td>
                            <b>Weakly Supervised 3D Segmentation via Receptive-driven Pseudo Label Consistency and Structural Consistency</b>
                    <br>
                    Yuxiang Lan<strong>1Ô∏è‚É£</strong>, <strong>Yachao Zhang1Ô∏è‚É£</strong>, Yanyun Qu, Cong Wang, Yuan Xie, Zongze Wu. 
                    <br>
                    <em>Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023)</em>
                    <br>
                    [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/25205">Paper</a>][<a href="https://github.com/Yachao-Zhang/DoubleConsistency">Code</a>]
                    </td>  
               </tr>
                   <tr>
                    <td width="40%">
                        <img width="320" src="../images/vsboost.jpg" border="0">
                            </td>
                    <td>
                            <b>VS-Boost: Boosting Visual-Semantic Association for Generalized Zero-Shot Learning</b>
                    <br>
                    Xiaofan Li, <strong>Yachao Zhang</strong> üìß, Shiran Bian, Yanyun Qu, Yuan Xie, Zhongchao Shi, Jianping Fan.
                    <br>
                    <em>International Joint Conference on Artificial Intelligence (IJCAI 2023)</em>
                    <br>
                   [<a href="https://www.ijcai.org/proceedings/2023/0123.pdf">Paper</a>]
                    </td>
               </tr>
                    <tr>
                    <td width="40%">
                        <img width="320" src="../images/BEV-DG.png" border="0">
                            </td>
                    <td>
                            <b>BEV-DG: Cross-Modal Learning under Bird‚Äôs-Eye View for Domain Generalization of 3D Semantic Segmentation</b>
                    <br>
                    Miaoyu Li, <strong>Yachao Zhang</strong> üìß, Xu Ma, Yanyun Qu, Yun Fu.
                    <br>
                    <em>IEEE/CVF International Conference on Computer Vision (ICCV 2023)</em>
                    <br>
                   [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Li_BEV-DG_Cross-Modal_Learning_under_Birds-Eye_View_for_Domain_Generalization_of_ICCV_2023_paper.pdf">Paper</a>][<a href="https://github.com/Yachao-Zhang">Code coming soon!</a>]
                    </td>
               </tr>
                     <tr>
                    <td width="40%">
                        <img width="320" src="../images/ann2snn.jpg" border="0">
                            </td>
                    <td>
                            <b>Efficient Converted Spiking Neural Network for 3D and 2D Classification</b>
                    <br>
                    Yuxiang Lan, <strong>Yachao Zhang</strong> üìß, Xu Ma, Yanyun Qu, Yun Fu.
                    <br>
                    <em>IEEE/CVF International Conference on Computer Vision (ICCV 2023)</em>
                    <br>
                    [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Lan_Efficient_Converted_Spiking_Neural_Network_for_3D_and_2D_Classification_ICCV_2023_paper.pdf">Paper</a>][<a href="https://github.com/Yachao-Zhang">Code coming soon!</a>]
                    </td>
               </tr>
               <tr>
                    <td width="40%">
                        <img width="320" src="../images/dist.jpg" border="0">
                            </td>
                    <td>
                            <b>Dual Pseudo-Labels Interactive Self-Training for Semi-Supervised Visible-Infrared Person Re-Identification</b>
                    <br>
                     Jiangming Shi<strong>1Ô∏è‚É£</strong>, <strong>Yachao Zhang1Ô∏è‚É£</strong>, Xiangbo Yin, Yuan Xie, Zhizhong Zhang, Jianping Fan, zhongchao shi, Yanyun Qu.
                    <br>
                    <em>IEEE/CVF International Conference on Computer Vision (ICCV 2023)</em>
                    <br>
                   [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Shi_Dual_Pseudo-Labels_Interactive_Self-Training_for_Semi-Supervised_Visible-Infrared_Person_Re-Identification_ICCV_2023_paper.pdf">Paper</a>][<a href="https://github.com/XiangboYin/DPIS_USVLReID">Code</a>]
                    </td>
               </tr>
                <tr>
                    <td width="40%">
                        <img width="320" src="../images/xmatch.jpg" border="0">
                            </td>
                    <td>
                            <b>Cross-Modal Match for Language Conditioned 3D Object Grounding</b>
                    <br>
                    <strong>Yachao Zhang</strong>, Runze Hu, Ronghui Li, Yanyun Qu, Yuan Xie, Xiu Liüìß.
                    <br>
                    <em>Association for the Advance of Artificial Intelligence (AAAI 2024)</em>
                    <br>
                    [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/28566">Paper</a>][<a href="https://github.com/Yachao-Zhang">Code coming soon!</a>]
                    </td>
               </tr>
               <tr>
                    <td width="40%">
                        <img width="320" src="../images/gesture.jpg" border="0">
                            </td>
                    <td>
                            <b>Chain of Generation: Multi-Modal Gesture Synthesis via Cascaded Conditional Control</b>
                    <br>
                     Zunnan XuÔºå<strong>Yachao Zhang</strong>üìßÔºåSicheng YangÔºåRonghui LiÔºåXiu Liüìß.
                    <br>
                    <em>Association for the Advance of Artificial Intelligence (AAAI 2024)</em>
                    <br>
                   [<a href="https://arxiv.org/abs/2312.15900">Paper</a>][<a href="https://github.com/Yachao-Zhang">Code coming soon!</a>]
                    </td>
               </tr>
                    </tbody>
           </table>
</font>


[Please visit [my google scholar profile](https://scholar.google.com/citations?user=a-I8c8EAAAAJ&hl=en) for the full publication list.]

_______________________________________________________________________________________________________

<h3>
  <a name="services"></a> üì†Academic Services
</h3>
<div class="mini">
  <ul>
  <li> <strong>Conference Reviewer</strong>: CVPR, ICML, NeurIPS, AAAI, ICCV, ACMMM, ICLR </li>
  <li> <strong>Journal Reviewer</strong>: IEEE Transactions on Neural Networks and Learning Systems, IEEE Transactions on Intelligent Transportation Systems, IEEE Transactions on Artificial Intelligence, IEEE Transactions on Image Processing</li>
  </ul>
</div>
 
_______________________________________________________________________________________________________

<h3>
  <a name="services"></a> ‚ú®Hobby
</h3>
<div class="mini">
 <td width="30%">
 <img width="60" src="../images/ball.jpg" border="0">
</td>
   <td width="30%">
 <img width="60" src="../images/reading.jpg" border="0">
</td>
   <td width="30%">
 <img width="60" src="../images/riding.jpg" border="0">
</td>
   <td width="30%">
 <img width="60" src="../images/tubu.jpg" border="0">
</td>
</div>

 
_______________________________________________________________________________________________________

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=ve6F6SS11iG4uIguoTWVRUjvilkuBNsM2hxvFs-6aos&cl=ffffff&w=a"></script>
